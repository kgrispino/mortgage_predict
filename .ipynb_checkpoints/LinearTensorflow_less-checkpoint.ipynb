{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_type               0\n",
      "property_type           0\n",
      "loan_purpose            0\n",
      "occupancy               0\n",
      "loan_amount             0\n",
      "preapproval             0\n",
      "msa_md                  0\n",
      "county_code             0\n",
      "applicant_race          0\n",
      "applicant_sex           0\n",
      "applicant_income    10708\n",
      "lender                  0\n",
      "rate_spread             0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_type</th>\n",
       "      <th>property_type</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>preapproval</th>\n",
       "      <th>msa_md</th>\n",
       "      <th>county_code</th>\n",
       "      <th>applicant_race</th>\n",
       "      <th>applicant_sex</th>\n",
       "      <th>applicant_income</th>\n",
       "      <th>lender</th>\n",
       "      <th>rate_spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>261</td>\n",
       "      <td>246</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>349</td>\n",
       "      <td>311</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4194</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>3</td>\n",
       "      <td>385</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1119</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>117</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1119</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>192</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1593</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>181</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>232</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3924</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>249</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>255</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2712</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loan_type  property_type  loan_purpose  occupancy  loan_amount  \\\n",
       "0               2              1             1          1          139   \n",
       "1               2              2             1          1          160   \n",
       "2               1              2             1          1          168   \n",
       "3               1              2             1          1           57   \n",
       "4               2              1             2          1           25   \n",
       "...           ...            ...           ...        ...          ...   \n",
       "199995          1              1             3          1           24   \n",
       "199996          1              2             1          1           20   \n",
       "199997          4              1             3          1           67   \n",
       "199998          2              1             3          1          330   \n",
       "199999          2              1             2          1           11   \n",
       "\n",
       "        preapproval  msa_md  county_code  applicant_race  applicant_sex  \\\n",
       "0                 1     261          246               5              1   \n",
       "1                 3     349          311               5              1   \n",
       "2                 3     385          256               2              1   \n",
       "3                 3     117           46               6              1   \n",
       "4                 3      95          192               5              2   \n",
       "...             ...     ...          ...             ...            ...   \n",
       "199995            3      96          181               5              2   \n",
       "199996            3     261          232               5              2   \n",
       "199997            3     261           52               5              1   \n",
       "199998            3      29          249               5              1   \n",
       "199999            3      43          255               5              1   \n",
       "\n",
       "        applicant_income  lender  rate_spread  \n",
       "0                   77.0    2094            1  \n",
       "1                   42.0    4194            2  \n",
       "2                   34.0    1119            3  \n",
       "3                   37.0    1119            6  \n",
       "4                   46.0    1593            4  \n",
       "...                  ...     ...          ...  \n",
       "199995              26.0    1249            1  \n",
       "199996              28.0    3924            5  \n",
       "199997               NaN    3864            1  \n",
       "199998               NaN    1645            1  \n",
       "199999              70.0    2712            6  \n",
       "\n",
       "[200000 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "plt.gcf().subplots_adjust(bottom=0.30)\n",
    "train = pd.read_csv('train_values.csv')\n",
    "#corr = train.corr()\n",
    "#sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True), square=True)\n",
    "train\n",
    "#plt.savefig(\"plot.svg\")\n",
    "#train = train.fillna(train.mean())\n",
    "\n",
    "#print(train.isna().sum())\n",
    "#X = train[[col for col in train.columns if col != 'rate_spread']]\n",
    "X = train[[col for col in train.columns if col != 'row_id']]\n",
    "#X = X[[col for col in X.columns if col != 'applicant_income']]\n",
    "X = X[[col for col in X.columns if col != 'population']]\n",
    "X = X[[col for col in X.columns if col != 'state_code']] #Contains -1 as a null\n",
    "X = X[[col for col in X.columns if col != 'minority_population_pct']]\n",
    "X = X[[col for col in X.columns if col != 'ffiecmedian_family_income']]\n",
    "X = X[[col for col in X.columns if col != 'tract_to_msa_md_income_pct']]\n",
    "X = X[[col for col in X.columns if col != 'number_of_owner-occupied_units']]\n",
    "X = X[[col for col in X.columns if col != 'number_of_1_to_4_family_units']]\n",
    "X = X[[col for col in X.columns if col != 'applicant_ethnicity']]\n",
    "X = X[[col for col in X.columns if col != 'co_applicant']]\n",
    "X = X[[col for col in X.columns if col != 'applicant_income']]\n",
    "X = X[[col for col in X.columns if col != 'number_of_1_to_4_family_units']]\n",
    "#X = X[[col for col in X.columns if col != 'loan_type']]\n",
    "y = train['rate_spread']\n",
    "print(X.isna().sum())\n",
    "\n",
    "#X['co_applicant'] = X['co_applicant'].map(lambda x: {1: 'co_applicant: True'}.get(x))\n",
    "#X = pd.get_dummies(X, prefix='', prefix_sep='')\n",
    "X\n",
    "#corr = X.corr()\n",
    "#sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True), square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_values.csv')\n",
    "test = test.fillna(test.mean())\n",
    "\n",
    "y = test[[col for col in test.columns if col != 'row_id']]\n",
    "#y = y[[col for col in y.columns if col != 'applicant_income']]\n",
    "y = y[[col for col in y.columns if col != 'population']]\n",
    "#y = y[[col for col in y.columns if col != 'minority_population_pct']]\n",
    "#y = y[[col for col in y.columns if col != 'ffiecmedian_family_income']]\n",
    "#y = y[[col for col in y.columns if col != 'tract_to_msa_md_income_pct']]\n",
    "#y = y[[col for col in y.columns if col != 'number_of_owner-occupied_units']]\n",
    "y = y[[col for col in y.columns if col != 'state_code']]\n",
    "y = y[[col for col in y.columns if col != 'number_of_1_to_4_family_units']]\n",
    "#y = y[[col for col in y.columns if col != 'loan_type']]\n",
    "\n",
    "y['co_applicant'] = y['co_applicant'].map(lambda q: {1: 'co_applicant: True'}.get(q))\n",
    "test = pd.get_dummies(y, prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = X.sample(frac=0.8,random_state=0)\n",
    "test_dataset = X.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_type</th>\n",
       "      <th>property_type</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>preapproval</th>\n",
       "      <th>msa_md</th>\n",
       "      <th>county_code</th>\n",
       "      <th>applicant_ethnicity</th>\n",
       "      <th>applicant_race</th>\n",
       "      <th>applicant_sex</th>\n",
       "      <th>applicant_income</th>\n",
       "      <th>minority_population_pct</th>\n",
       "      <th>ffiecmedian_family_income</th>\n",
       "      <th>tract_to_msa_md_income_pct</th>\n",
       "      <th>number_of_owner-occupied_units</th>\n",
       "      <th>lender</th>\n",
       "      <th>rate_spread</th>\n",
       "      <th>co_applicant: True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>3</td>\n",
       "      <td>385</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>79.635</td>\n",
       "      <td>42883.0</td>\n",
       "      <td>76.948</td>\n",
       "      <td>636.0</td>\n",
       "      <td>1119</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>261</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>14.353</td>\n",
       "      <td>48288.0</td>\n",
       "      <td>79.629</td>\n",
       "      <td>854.0</td>\n",
       "      <td>516</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>78.274</td>\n",
       "      <td>37781.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2334.0</td>\n",
       "      <td>683</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>261</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>307</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>5.563</td>\n",
       "      <td>69544.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>2390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>2</td>\n",
       "      <td>340</td>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>9.760</td>\n",
       "      <td>58537.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>809</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199976</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>7.288</td>\n",
       "      <td>62102.0</td>\n",
       "      <td>83.508</td>\n",
       "      <td>1484.0</td>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199978</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>10.827</td>\n",
       "      <td>66608.0</td>\n",
       "      <td>93.233</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>1066</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199986</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>358</td>\n",
       "      <td>246</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>28.001</td>\n",
       "      <td>68268.0</td>\n",
       "      <td>82.566</td>\n",
       "      <td>1323.0</td>\n",
       "      <td>2657</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>73.617902</td>\n",
       "      <td>4.093</td>\n",
       "      <td>55918.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>3864</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>255</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>13.632</td>\n",
       "      <td>74058.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1857.0</td>\n",
       "      <td>2712</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loan_type  property_type  loan_purpose  occupancy  loan_amount  \\\n",
       "2               1              2             1          1          168   \n",
       "10              1              2             1          2           80   \n",
       "21              1              1             1          1          181   \n",
       "27              1              1             3          1          261   \n",
       "30              2              1             1          1          170   \n",
       "...           ...            ...           ...        ...          ...   \n",
       "199976          2              1             1          1          119   \n",
       "199978          1              2             3          1           29   \n",
       "199986          2              1             2          1          102   \n",
       "199997          4              1             3          1           67   \n",
       "199999          2              1             2          1           11   \n",
       "\n",
       "        preapproval  msa_md  county_code  applicant_ethnicity  applicant_race  \\\n",
       "2                 3     385          256                    3               2   \n",
       "10                2     261           78                    3               3   \n",
       "21                3      60           14                    2               5   \n",
       "27                3      33          307                    2               5   \n",
       "30                2     340           84                    3               6   \n",
       "...             ...     ...          ...                  ...             ...   \n",
       "199976            2      79           92                    2               5   \n",
       "199978            3     163           41                    2               3   \n",
       "199986            3     358          246                    3               6   \n",
       "199997            3     261           52                    2               5   \n",
       "199999            3      43          255                    2               5   \n",
       "\n",
       "        applicant_sex  applicant_income  minority_population_pct  \\\n",
       "2                   1         34.000000                   79.635   \n",
       "10                  1         49.000000                   14.353   \n",
       "21                  2        148.000000                   78.274   \n",
       "27                  1        217.000000                    5.563   \n",
       "30                  2         95.000000                    9.760   \n",
       "...               ...               ...                      ...   \n",
       "199976              2        101.000000                    7.288   \n",
       "199978              1         33.000000                   10.827   \n",
       "199986              3         47.000000                   28.001   \n",
       "199997              1         73.617902                    4.093   \n",
       "199999              1         70.000000                   13.632   \n",
       "\n",
       "        ffiecmedian_family_income  tract_to_msa_md_income_pct  \\\n",
       "2                         42883.0                      76.948   \n",
       "10                        48288.0                      79.629   \n",
       "21                        37781.0                     100.000   \n",
       "27                        69544.0                     100.000   \n",
       "30                        58537.0                     100.000   \n",
       "...                           ...                         ...   \n",
       "199976                    62102.0                      83.508   \n",
       "199978                    66608.0                      93.233   \n",
       "199986                    68268.0                      82.566   \n",
       "199997                    55918.0                     100.000   \n",
       "199999                    74058.0                     100.000   \n",
       "\n",
       "        number_of_owner-occupied_units  lender  rate_spread  \\\n",
       "2                                636.0    1119            3   \n",
       "10                               854.0     516            2   \n",
       "21                              2334.0     683            3   \n",
       "27                              1142.0    2390            1   \n",
       "30                              1083.0     809            1   \n",
       "...                                ...     ...          ...   \n",
       "199976                          1484.0     516            1   \n",
       "199978                          1907.0    1066            2   \n",
       "199986                          1323.0    2657            1   \n",
       "199997                          2034.0    3864            1   \n",
       "199999                          1857.0    2712            6   \n",
       "\n",
       "        co_applicant: True  \n",
       "2                        0  \n",
       "10                       0  \n",
       "21                       0  \n",
       "27                       0  \n",
       "30                       1  \n",
       "...                    ...  \n",
       "199976                   0  \n",
       "199978                   0  \n",
       "199986                   0  \n",
       "199997                   0  \n",
       "199999                   0  \n",
       "\n",
       "[40000 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loan_type</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>1.570963</td>\n",
       "      <td>0.559780</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>1.154469</td>\n",
       "      <td>0.364773</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_purpose</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>1.483062</td>\n",
       "      <td>0.822119</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupancy</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>1.061481</td>\n",
       "      <td>0.246326</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amount</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>142.668275</td>\n",
       "      <td>143.181301</td>\n",
       "      <td>1.000</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>116.000</td>\n",
       "      <td>179.00000</td>\n",
       "      <td>11104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preapproval</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>2.703038</td>\n",
       "      <td>0.545415</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msa_md</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>226.960981</td>\n",
       "      <td>106.664277</td>\n",
       "      <td>0.000</td>\n",
       "      <td>154.00000</td>\n",
       "      <td>261.000</td>\n",
       "      <td>318.00000</td>\n",
       "      <td>408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county_code</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>166.382362</td>\n",
       "      <td>92.834045</td>\n",
       "      <td>0.000</td>\n",
       "      <td>83.00000</td>\n",
       "      <td>181.000</td>\n",
       "      <td>249.00000</td>\n",
       "      <td>316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_ethnicity</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>1.915544</td>\n",
       "      <td>0.513323</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_race</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>4.762094</td>\n",
       "      <td>0.889283</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_sex</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>1.417225</td>\n",
       "      <td>0.577094</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_income</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>73.724018</td>\n",
       "      <td>103.020151</td>\n",
       "      <td>1.000</td>\n",
       "      <td>40.00000</td>\n",
       "      <td>59.000</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>9695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minority_population_pct</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>34.236370</td>\n",
       "      <td>27.811185</td>\n",
       "      <td>0.326</td>\n",
       "      <td>11.02900</td>\n",
       "      <td>26.329</td>\n",
       "      <td>51.65825</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffiecmedian_family_income</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>64590.332019</td>\n",
       "      <td>12678.232151</td>\n",
       "      <td>17860.000</td>\n",
       "      <td>56731.00000</td>\n",
       "      <td>63593.000</td>\n",
       "      <td>71172.00000</td>\n",
       "      <td>124934.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tract_to_msa_md_income_pct</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>89.306346</td>\n",
       "      <td>14.959711</td>\n",
       "      <td>6.193</td>\n",
       "      <td>81.88175</td>\n",
       "      <td>98.676</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_owner-occupied_units</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>1401.689477</td>\n",
       "      <td>700.044618</td>\n",
       "      <td>3.000</td>\n",
       "      <td>936.00000</td>\n",
       "      <td>1311.000</td>\n",
       "      <td>1735.00000</td>\n",
       "      <td>8747.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lender</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>2002.863125</td>\n",
       "      <td>1270.942368</td>\n",
       "      <td>0.000</td>\n",
       "      <td>963.00000</td>\n",
       "      <td>1834.000</td>\n",
       "      <td>3180.00000</td>\n",
       "      <td>4283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co_applicant: True</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>0.383650</td>\n",
       "      <td>0.486276</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   count          mean           std  \\\n",
       "loan_type                       160000.0      1.570963      0.559780   \n",
       "property_type                   160000.0      1.154469      0.364773   \n",
       "loan_purpose                    160000.0      1.483062      0.822119   \n",
       "occupancy                       160000.0      1.061481      0.246326   \n",
       "loan_amount                     160000.0    142.668275    143.181301   \n",
       "preapproval                     160000.0      2.703038      0.545415   \n",
       "msa_md                          160000.0    226.960981    106.664277   \n",
       "county_code                     160000.0    166.382362     92.834045   \n",
       "applicant_ethnicity             160000.0      1.915544      0.513323   \n",
       "applicant_race                  160000.0      4.762094      0.889283   \n",
       "applicant_sex                   160000.0      1.417225      0.577094   \n",
       "applicant_income                160000.0     73.724018    103.020151   \n",
       "minority_population_pct         160000.0     34.236370     27.811185   \n",
       "ffiecmedian_family_income       160000.0  64590.332019  12678.232151   \n",
       "tract_to_msa_md_income_pct      160000.0     89.306346     14.959711   \n",
       "number_of_owner-occupied_units  160000.0   1401.689477    700.044618   \n",
       "lender                          160000.0   2002.863125   1270.942368   \n",
       "co_applicant: True              160000.0      0.383650      0.486276   \n",
       "\n",
       "                                      min          25%        50%  \\\n",
       "loan_type                           1.000      1.00000      2.000   \n",
       "property_type                       1.000      1.00000      1.000   \n",
       "loan_purpose                        1.000      1.00000      1.000   \n",
       "occupancy                           1.000      1.00000      1.000   \n",
       "loan_amount                         1.000     67.00000    116.000   \n",
       "preapproval                         1.000      2.00000      3.000   \n",
       "msa_md                              0.000    154.00000    261.000   \n",
       "county_code                         0.000     83.00000    181.000   \n",
       "applicant_ethnicity                 1.000      2.00000      2.000   \n",
       "applicant_race                      1.000      5.00000      5.000   \n",
       "applicant_sex                       1.000      1.00000      1.000   \n",
       "applicant_income                    1.000     40.00000     59.000   \n",
       "minority_population_pct             0.326     11.02900     26.329   \n",
       "ffiecmedian_family_income       17860.000  56731.00000  63593.000   \n",
       "tract_to_msa_md_income_pct          6.193     81.88175     98.676   \n",
       "number_of_owner-occupied_units      3.000    936.00000   1311.000   \n",
       "lender                              0.000    963.00000   1834.000   \n",
       "co_applicant: True                  0.000      0.00000      0.000   \n",
       "\n",
       "                                        75%       max  \n",
       "loan_type                           2.00000       4.0  \n",
       "property_type                       1.00000       3.0  \n",
       "loan_purpose                        2.00000       3.0  \n",
       "occupancy                           1.00000       3.0  \n",
       "loan_amount                       179.00000   11104.0  \n",
       "preapproval                         3.00000       3.0  \n",
       "msa_md                            318.00000     408.0  \n",
       "county_code                       249.00000     316.0  \n",
       "applicant_ethnicity                 2.00000       4.0  \n",
       "applicant_race                      5.00000       7.0  \n",
       "applicant_sex                       2.00000       4.0  \n",
       "applicant_income                   80.00000    9695.0  \n",
       "minority_population_pct            51.65825     100.0  \n",
       "ffiecmedian_family_income       71172.00000  124934.0  \n",
       "tract_to_msa_md_income_pct        100.00000     100.0  \n",
       "number_of_owner-occupied_units   1735.00000    8747.0  \n",
       "lender                           3180.00000    4283.0  \n",
       "co_applicant: True                  1.00000       1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats = train_dataset.describe()\n",
    "train_stats.pop(\"rate_spread\")\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset.pop('rate_spread')\n",
    "test_labels = test_dataset.pop('rate_spread')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)\n",
    "normed_test = norm(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "\n",
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  #optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "  #model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "  #optimizer = SGD\n",
    "  model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=[coeff_determination])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 100 == 0: print('')\n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Abs Error [Rate Spread]')\n",
    "  plt.plot(hist['epoch'], hist['coeff_determination'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_coeff_determination'],\n",
    "           label = 'Val Error')\n",
    "  plt.ylim([.4,1])\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/300\n",
      "127552/128000 [============================>.] - ETA: 0s - loss: 1.4920 - coeff_determination: 0.4412- ETA\n",
      "128000/128000 [==============================] - 8s 66us/sample - loss: 1.4907 - coeff_determination: 0.4416 - val_loss: 1.1524 - val_coeff_determination: 0.5118\n",
      "Epoch 2/300\n",
      "128000/128000 [==============================] - 9s 72us/sample - loss: 1.3006 - coeff_determination: 0.5183 - val_loss: 1.1205 - val_coeff_determination: 0.5107\n",
      "Epoch 3/300\n",
      "128000/128000 [==============================] - 9s 67us/sample - loss: 1.2496 - coeff_determination: 0.5409 - val_loss: 1.0909 - val_coeff_determination: 0.5437\n",
      "Epoch 4/300\n",
      "128000/128000 [==============================] - 9s 69us/sample - loss: 1.2158 - coeff_determination: 0.5456 - val_loss: 1.0802 - val_coeff_determination: 0.5509\n",
      "Epoch 5/300\n",
      "128000/128000 [==============================] - 10s 81us/sample - loss: 1.2020 - coeff_determination: 0.5499 - val_loss: 1.0402 - val_coeff_determination: 0.5591\n",
      "Epoch 6/300\n",
      "128000/128000 [==============================] - 12s 95us/sample - loss: 1.1786 - coeff_determination: 0.5623 - val_loss: 1.0486 - val_coeff_determination: 0.5555\n",
      "Epoch 7/300\n",
      "128000/128000 [==============================] - 12s 91us/sample - loss: 1.1624 - coeff_determination: 0.5604 - val_loss: 1.0419 - val_coeff_determination: 0.5564\n",
      "Epoch 8/300\n",
      "128000/128000 [==============================] - 12s 94us/sample - loss: 1.1426 - coeff_determination: 0.5650 - val_loss: 1.0464 - val_coeff_determination: 0.5488\n",
      "Epoch 9/300\n",
      "128000/128000 [==============================] - 12s 93us/sample - loss: 1.1133 - coeff_determination: 0.5655 - val_loss: 1.0742 - val_coeff_determination: 0.5514\n",
      "Epoch 10/300\n",
      "128000/128000 [==============================] - 11s 83us/sample - loss: 1.1153 - coeff_determination: 0.5669 - val_loss: 1.0489 - val_coeff_determination: 0.5478\n",
      "Epoch 11/300\n",
      "128000/128000 [==============================] - 9s 67us/sample - loss: 1.0944 - coeff_determination: 0.5638 - val_loss: 1.0462 - val_coeff_determination: 0.5637\n",
      "Epoch 12/300\n",
      "128000/128000 [==============================] - 8s 65us/sample - loss: 1.0893 - coeff_determination: 0.5655 - val_loss: 1.0655 - val_coeff_determination: 0.5468\n",
      "Epoch 13/300\n",
      "128000/128000 [==============================] - 8s 64us/sample - loss: 1.0572 - coeff_determination: 0.5694 - val_loss: 1.0292 - val_coeff_determination: 0.5647loss: 1.0158 - \n",
      "Epoch 14/300\n",
      "128000/128000 [==============================] - 8s 65us/sample - loss: 1.0441 - coeff_determination: 0.5739 - val_loss: 1.0174 - val_coeff_determination: 0.5646 4s - loss:\n",
      "Epoch 15/300\n",
      "128000/128000 [==============================] - 9s 68us/sample - loss: 1.0585 - coeff_determination: 0.5716 - val_loss: 1.0223 - val_coeff_determination: 0.5730\n",
      "Epoch 16/300\n",
      "128000/128000 [==============================] - 15s 115us/sample - loss: 1.0076 - coeff_determination: 0.5753 - val_loss: 1.0292 - val_coeff_determination: 0.5681\n",
      "Epoch 17/300\n",
      "128000/128000 [==============================] - 12s 97us/sample - loss: 1.0087 - coeff_determination: 0.5760 - val_loss: 1.0476 - val_coeff_determination: 0.5690\n",
      "Epoch 18/300\n",
      "128000/128000 [==============================] - 13s 99us/sample - loss: 1.0087 - coeff_determination: 0.5672 - val_loss: 1.0357 - val_coeff_determination: 0.5593.9578 - coeff_determina - ETA: 3s - loss: 0.9610 - coeff_determinatio\n",
      "Epoch 19/300\n",
      "128000/128000 [==============================] - 12s 91us/sample - loss: 0.9650 - coeff_determination: 0.5822 - val_loss: 1.0177 - val_coeff_determination: 0.5621\n",
      "Epoch 20/300\n",
      "128000/128000 [==============================] - 12s 94us/sample - loss: 0.9591 - coeff_determination: 0.5817 - val_loss: 1.0274 - val_coeff_determination: 0.5604\n",
      "Epoch 21/300\n",
      "128000/128000 [==============================] - 12s 92us/sample - loss: 0.9703 - coeff_determination: 0.5877 - val_loss: 1.0222 - val_coeff_determination: 0.5707\n",
      "Epoch 22/300\n",
      "128000/128000 [==============================] - 12s 93us/sample - loss: 0.9829 - coeff_determination: 0.5801 - val_loss: 1.0059 - val_coeff_determination: 0.5746\n",
      "Epoch 23/300\n",
      "128000/128000 [==============================] - 13s 100us/sample - loss: 0.9395 - coeff_determination: 0.5853 - val_loss: 1.0157 - val_coeff_determination: 0.5662\n",
      "Epoch 24/300\n",
      "128000/128000 [==============================] - 11s 85us/sample - loss: 0.9452 - coeff_determination: 0.5947 - val_loss: 1.0136 - val_coeff_determination: 0.5658\n",
      "Epoch 25/300\n",
      "128000/128000 [==============================] - 12s 94us/sample - loss: 0.9479 - coeff_determination: 0.5875 - val_loss: 1.0259 - val_coeff_determination: 0.5765\n",
      "Epoch 26/300\n",
      "128000/128000 [==============================] - 12s 92us/sample - loss: 0.9416 - coeff_determination: 0.5940 - val_loss: 1.0060 - val_coeff_determination: 0.5646\n",
      "Epoch 27/300\n",
      "128000/128000 [==============================] - 12s 91us/sample - loss: 1.0000 - coeff_determination: 0.5865 - val_loss: 1.0011 - val_coeff_determination: 0.5788\n",
      "Epoch 28/300\n",
      "128000/128000 [==============================] - 13s 98us/sample - loss: 0.9335 - coeff_determination: 0.5963 - val_loss: 1.0079 - val_coeff_determination: 0.5644\n",
      "Epoch 29/300\n",
      "128000/128000 [==============================] - 12s 95us/sample - loss: 0.9340 - coeff_determination: 0.5969 - val_loss: 1.0100 - val_coeff_determination: 0.5721\n",
      "Epoch 30/300\n",
      "128000/128000 [==============================] - 11s 82us/sample - loss: 0.9792 - coeff_determination: 0.6012 - val_loss: 0.9889 - val_coeff_determination: 0.5746\n",
      "Epoch 31/300\n",
      "128000/128000 [==============================] - 13s 98us/sample - loss: 0.9367 - coeff_determination: 0.5964 - val_loss: 0.9979 - val_coeff_determination: 0.5742\n",
      "Epoch 32/300\n",
      "128000/128000 [==============================] - 12s 96us/sample - loss: 0.9480 - coeff_determination: 0.5993 - val_loss: 0.9874 - val_coeff_determination: 0.5876\n",
      "Epoch 33/300\n",
      "128000/128000 [==============================] - 13s 98us/sample - loss: 0.9517 - coeff_determination: 0.6049 - val_loss: 0.9991 - val_coeff_determination: 0.5830\n",
      "Epoch 34/300\n",
      "128000/128000 [==============================] - 11s 87us/sample - loss: 0.9218 - coeff_determination: 0.5945 - val_loss: 0.9939 - val_coeff_determination: 0.5805\n",
      "Epoch 35/300\n",
      "128000/128000 [==============================] - 11s 89us/sample - loss: 0.9804 - coeff_determination: 0.6054 - val_loss: 0.9919 - val_coeff_determination: 0.5803\n",
      "Epoch 36/300\n",
      "128000/128000 [==============================] - 12s 96us/sample - loss: 0.8983 - coeff_determination: 0.6111 - val_loss: 0.9839 - val_coeff_determination: 0.5802\n",
      "Epoch 37/300\n",
      "128000/128000 [==============================] - 13s 99us/sample - loss: 0.9052 - coeff_determination: 0.6082 - val_loss: 0.9873 - val_coeff_determination: 0.5868\n",
      "Epoch 38/300\n",
      "128000/128000 [==============================] - 12s 95us/sample - loss: 0.9114 - coeff_determination: 0.6068 - val_loss: 0.9863 - val_coeff_determination: 0.5836\n",
      "Epoch 39/300\n",
      "128000/128000 [==============================] - 11s 85us/sample - loss: 0.9645 - coeff_determination: 0.6060 - val_loss: 1.0283 - val_coeff_determination: 0.5821\n",
      "Epoch 40/300\n",
      "128000/128000 [==============================] - 13s 101us/sample - loss: 0.9290 - coeff_determination: 0.6033 - val_loss: 0.9950 - val_coeff_determination: 0.5876\n",
      "Epoch 41/300\n",
      "128000/128000 [==============================] - 17s 136us/sample - loss: 0.9062 - coeff_determination: 0.6128 - val_loss: 0.9829 - val_coeff_determination: 0.5830\n",
      "Epoch 42/300\n",
      "128000/128000 [==============================] - 12s 95us/sample - loss: 0.9645 - coeff_determination: 0.6118 - val_loss: 0.9777 - val_coeff_determination: 0.5937\n",
      "Epoch 43/300\n",
      "128000/128000 [==============================] - 13s 102us/sample - loss: 0.9430 - coeff_determination: 0.6105 - val_loss: 1.0079 - val_coeff_determination: 0.5761\n",
      "Epoch 44/300\n",
      "128000/128000 [==============================] - 13s 98us/sample - loss: 0.8862 - coeff_determination: 0.6159 - val_loss: 0.9701 - val_coeff_determination: 0.5891\n",
      "Epoch 45/300\n",
      "128000/128000 [==============================] - 12s 90us/sample - loss: 0.9023 - coeff_determination: 0.6175 - val_loss: 0.9751 - val_coeff_determination: 0.5941n: 0.6174\n",
      "Epoch 46/300\n",
      "128000/128000 [==============================] - 13s 100us/sample - loss: 0.8995 - coeff_determination: 0.6124 - val_loss: 0.9949 - val_coeff_determination: 0.5887\n",
      "Epoch 47/300\n",
      "128000/128000 [==============================] - 13s 100us/sample - loss: 0.8884 - coeff_determination: 0.6061 - val_loss: 0.9772 - val_coeff_determination: 0.5864\n",
      "Epoch 48/300\n",
      "128000/128000 [==============================] - 12s 92us/sample - loss: 0.8723 - coeff_determination: 0.6176 - val_loss: 0.9939 - val_coeff_determination: 0.5747\n",
      "Epoch 49/300\n",
      "128000/128000 [==============================] - 16s 126us/sample - loss: 0.9226 - coeff_determination: 0.6155 - val_loss: 0.9969 - val_coeff_determination: 0.5813\n",
      "Epoch 50/300\n",
      "128000/128000 [==============================] - 9s 71us/sample - loss: 0.9110 - coeff_determination: 0.6186 - val_loss: 0.9730 - val_coeff_determination: 0.5804\n",
      "Epoch 51/300\n",
      "128000/128000 [==============================] - 8s 62us/sample - loss: 0.9074 - coeff_determination: 0.6156 - val_loss: 0.9947 - val_coeff_determination: 0.5891\n",
      "Epoch 52/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.8991 - coeff_determination: 0.6169 - val_loss: 0.9825 - val_coeff_determination: 0.5880\n",
      "Epoch 53/300\n",
      "128000/128000 [==============================] - 6s 50us/sample - loss: 0.8935 - coeff_determination: 0.6246 - val_loss: 0.9758 - val_coeff_determination: 0.5783\n",
      "Epoch 54/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.9014 - coeff_determination: 0.6195 - val_loss: 0.9720 - val_coeff_determination: 0.5936\n",
      "Epoch 55/300\n",
      "128000/128000 [==============================] - 8s 61us/sample - loss: 0.8645 - coeff_determination: 0.6264 - val_loss: 0.9711 - val_coeff_determination: 0.5939\n",
      "Epoch 56/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8731 - coeff_determination: 0.6199 - val_loss: 0.9837 - val_coeff_determination: 0.5789\n",
      "Epoch 57/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.9283 - coeff_determination: 0.6176 - val_loss: 0.9693 - val_coeff_determination: 0.5842\n",
      "Epoch 58/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.9108 - coeff_determination: 0.6186 - val_loss: 0.9736 - val_coeff_determination: 0.5916\n",
      "Epoch 59/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8775 - coeff_determination: 0.6236 - val_loss: 1.0577 - val_coeff_determination: 0.5524\n",
      "Epoch 60/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.9300 - coeff_determination: 0.6185 - val_loss: 0.9806 - val_coeff_determination: 0.5737\n",
      "Epoch 61/300\n",
      "128000/128000 [==============================] - 6s 50us/sample - loss: 0.8687 - coeff_determination: 0.6211 - val_loss: 0.9954 - val_coeff_determination: 0.5830\n",
      "Epoch 62/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.9502 - coeff_determination: 0.6232 - val_loss: 0.9651 - val_coeff_determination: 0.5920\n",
      "Epoch 63/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8714 - coeff_determination: 0.6236 - val_loss: 0.9792 - val_coeff_determination: 0.5845\n",
      "Epoch 64/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8941 - coeff_determination: 0.6236 - val_loss: 0.9658 - val_coeff_determination: 0.5937\n",
      "Epoch 65/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.9160 - coeff_determination: 0.6259 - val_loss: 1.0087 - val_coeff_determination: 0.5774\n",
      "Epoch 66/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.8465 - coeff_determination: 0.6269 - val_loss: 0.9660 - val_coeff_determination: 0.5938\n",
      "Epoch 67/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.8820 - coeff_determination: 0.6237 - val_loss: 0.9707 - val_coeff_determination: 0.5763\n",
      "Epoch 68/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8698 - coeff_determination: 0.6188 - val_loss: 0.9621 - val_coeff_determination: 0.5900\n",
      "Epoch 69/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8739 - coeff_determination: 0.6212 - val_loss: 0.9797 - val_coeff_determination: 0.5847\n",
      "Epoch 70/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8858 - coeff_determination: 0.6223 - val_loss: 0.9729 - val_coeff_determination: 0.5833\n",
      "Epoch 71/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.9161 - coeff_determination: 0.6260 - val_loss: 0.9586 - val_coeff_determination: 0.5920\n",
      "Epoch 72/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8412 - coeff_determination: 0.6274 - val_loss: 0.9698 - val_coeff_determination: 0.5832\n",
      "Epoch 73/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8776 - coeff_determination: 0.6244 - val_loss: 0.9680 - val_coeff_determination: 0.5968\n",
      "Epoch 74/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8869 - coeff_determination: 0.6232 - val_loss: 0.9615 - val_coeff_determination: 0.5889\n",
      "Epoch 75/300\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.8813 - coeff_determination: 0.6305 - val_loss: 0.9867 - val_coeff_determination: 0.5828\n",
      "Epoch 76/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8653 - coeff_determination: 0.6270 - val_loss: 0.9767 - val_coeff_determination: 0.5756\n",
      "Epoch 77/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8564 - coeff_determination: 0.6281 - val_loss: 0.9673 - val_coeff_determination: 0.5892\n",
      "Epoch 78/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8792 - coeff_determination: 0.6216 - val_loss: 0.9627 - val_coeff_determination: 0.5909\n",
      "Epoch 79/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8422 - coeff_determination: 0.6308 - val_loss: 0.9730 - val_coeff_determination: 0.5915\n",
      "Epoch 80/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.8648 - coeff_determination: 0.6272 - val_loss: 0.9672 - val_coeff_determination: 0.5865\n",
      "Epoch 81/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8710 - coeff_determination: 0.6244 - val_loss: 0.9913 - val_coeff_determination: 0.5775\n",
      "Epoch 82/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8570 - coeff_determination: 0.6307 - val_loss: 1.0357 - val_coeff_determination: 0.5418\n",
      "Epoch 83/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8475 - coeff_determination: 0.6283 - val_loss: 0.9879 - val_coeff_determination: 0.5818\n",
      "Epoch 84/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8444 - coeff_determination: 0.6292 - val_loss: 0.9624 - val_coeff_determination: 0.5954\n",
      "Epoch 85/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8677 - coeff_determination: 0.6314 - val_loss: 0.9880 - val_coeff_determination: 0.5767\n",
      "Epoch 86/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8684 - coeff_determination: 0.6331 - val_loss: 1.1157 - val_coeff_determination: 0.5056\n",
      "Epoch 87/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8939 - coeff_determination: 0.6280 - val_loss: 0.9729 - val_coeff_determination: 0.5842\n",
      "Epoch 88/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8398 - coeff_determination: 0.6276 - val_loss: 0.9679 - val_coeff_determination: 0.5924\n",
      "Epoch 89/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.8404 - coeff_determination: 0.6296 - val_loss: 0.9668 - val_coeff_determination: 0.5848\n",
      "Epoch 90/300\n",
      "128000/128000 [==============================] - 7s 58us/sample - loss: 0.8572 - coeff_determination: 0.6272 - val_loss: 0.9818 - val_coeff_determination: 0.5873\n",
      "Epoch 91/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8477 - coeff_determination: 0.6322 - val_loss: 0.9659 - val_coeff_determination: 0.5878\n",
      "Epoch 92/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.9120 - coeff_determination: 0.6320 - val_loss: 0.9590 - val_coeff_determination: 0.5868\n",
      "Epoch 93/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.8408 - coeff_determination: 0.6326 - val_loss: 0.9787 - val_coeff_determination: 0.5777\n",
      "Epoch 94/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.8482 - coeff_determination: 0.6325 - val_loss: 0.9767 - val_coeff_determination: 0.5818\n",
      "Epoch 95/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.8518 - coeff_determination: 0.6315 - val_loss: 0.9725 - val_coeff_determination: 0.5879\n",
      "Epoch 96/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8450 - coeff_determination: 0.6286 - val_loss: 1.0019 - val_coeff_determination: 0.5719\n",
      "Epoch 97/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8294 - coeff_determination: 0.6287 - val_loss: 0.9861 - val_coeff_determination: 0.5798\n",
      "Epoch 98/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8379 - coeff_determination: 0.6343 - val_loss: 0.9690 - val_coeff_determination: 0.5865\n",
      "Epoch 99/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8479 - coeff_determination: 0.6307 - val_loss: 0.9853 - val_coeff_determination: 0.5806\n",
      "Epoch 100/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.8328 - coeff_determination: 0.6353 - val_loss: 0.9790 - val_coeff_determination: 0.5840\n",
      "Epoch 101/300\n",
      "127456/128000 [============================>.] - ETA: 0s - loss: 0.8752 - coeff_determination: 0.6318\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.8745 - coeff_determination: 0.6321 - val_loss: 0.9899 - val_coeff_determination: 0.5736\n",
      "Epoch 102/300\n",
      "128000/128000 [==============================] - 6s 50us/sample - loss: 0.8488 - coeff_determination: 0.6345 - val_loss: 0.9661 - val_coeff_determination: 0.5866\n",
      "Epoch 103/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8590 - coeff_determination: 0.6295 - val_loss: 0.9673 - val_coeff_determination: 0.5895\n",
      "Epoch 104/300\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.8963 - coeff_determination: 0.6342 - val_loss: 0.9691 - val_coeff_determination: 0.5815\n",
      "Epoch 105/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8290 - coeff_determination: 0.6387 - val_loss: 0.9685 - val_coeff_determination: 0.5861\n",
      "Epoch 106/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8768 - coeff_determination: 0.6337 - val_loss: 0.9690 - val_coeff_determination: 0.5938\n",
      "Epoch 107/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8328 - coeff_determination: 0.6391 - val_loss: 0.9909 - val_coeff_determination: 0.5799\n",
      "Epoch 108/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.8334 - coeff_determination: 0.6331 - val_loss: 0.9642 - val_coeff_determination: 0.5940\n",
      "Epoch 109/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8456 - coeff_determination: 0.6339 - val_loss: 0.9736 - val_coeff_determination: 0.5891\n",
      "Epoch 110/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8307 - coeff_determination: 0.6396 - val_loss: 0.9765 - val_coeff_determination: 0.5683\n",
      "Epoch 111/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8352 - coeff_determination: 0.6331 - val_loss: 0.9696 - val_coeff_determination: 0.5791\n",
      "Epoch 112/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.8427 - coeff_determination: 0.6377 - val_loss: 0.9768 - val_coeff_determination: 0.5800\n",
      "Epoch 113/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.8498 - coeff_determination: 0.6364 - val_loss: 0.9631 - val_coeff_determination: 0.5842\n",
      "Epoch 114/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8479 - coeff_determination: 0.6308 - val_loss: 0.9647 - val_coeff_determination: 0.5934\n",
      "Epoch 115/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8315 - coeff_determination: 0.6341 - val_loss: 0.9852 - val_coeff_determination: 0.5776\n",
      "Epoch 116/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.8381 - coeff_determination: 0.6369 - val_loss: 0.9647 - val_coeff_determination: 0.5888\n",
      "Epoch 117/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.8325 - coeff_determination: 0.6354 - val_loss: 0.9618 - val_coeff_determination: 0.5859\n",
      "Epoch 118/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8256 - coeff_determination: 0.6358 - val_loss: 0.9617 - val_coeff_determination: 0.5903\n",
      "Epoch 119/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8320 - coeff_determination: 0.6368 - val_loss: 0.9665 - val_coeff_determination: 0.5938\n",
      "Epoch 120/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8269 - coeff_determination: 0.6402 - val_loss: 0.9679 - val_coeff_determination: 0.5840\n",
      "Epoch 121/300\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.8230 - coeff_determination: 0.6362 - val_loss: 0.9704 - val_coeff_determination: 0.5880\n",
      "Epoch 122/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8501 - coeff_determination: 0.6369 - val_loss: 0.9693 - val_coeff_determination: 0.5876\n",
      "Epoch 123/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8366 - coeff_determination: 0.6395 - val_loss: 0.9656 - val_coeff_determination: 0.5964\n",
      "Epoch 124/300\n",
      "128000/128000 [==============================] - 7s 58us/sample - loss: 0.8289 - coeff_determination: 0.6366 - val_loss: 0.9683 - val_coeff_determination: 0.5900\n",
      "Epoch 125/300\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.8490 - coeff_determination: 0.6385 - val_loss: 0.9642 - val_coeff_determination: 0.5916\n",
      "Epoch 126/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8261 - coeff_determination: 0.6401 - val_loss: 0.9648 - val_coeff_determination: 0.5933\n",
      "Epoch 127/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8199 - coeff_determination: 0.6395 - val_loss: 0.9775 - val_coeff_determination: 0.5845\n",
      "Epoch 128/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8158 - coeff_determination: 0.6372 - val_loss: 0.9707 - val_coeff_determination: 0.5873\n",
      "Epoch 129/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8274 - coeff_determination: 0.6361 - val_loss: 0.9714 - val_coeff_determination: 0.5835\n",
      "Epoch 130/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8363 - coeff_determination: 0.6387 - val_loss: 0.9669 - val_coeff_determination: 0.5733\n",
      "Epoch 131/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8272 - coeff_determination: 0.6384 - val_loss: 0.9674 - val_coeff_determination: 0.5896\n",
      "Epoch 132/300\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.8240 - coeff_determination: 0.6387 - val_loss: 0.9778 - val_coeff_determination: 0.5761\n",
      "Epoch 133/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8354 - coeff_determination: 0.6393 - val_loss: 0.9668 - val_coeff_determination: 0.5979\n",
      "Epoch 134/300\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.8244 - coeff_determination: 0.6387 - val_loss: 0.9912 - val_coeff_determination: 0.5783\n",
      "Epoch 135/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8187 - coeff_determination: 0.6438 - val_loss: 0.9663 - val_coeff_determination: 0.5897\n",
      "Epoch 136/300\n",
      "128000/128000 [==============================] - 6s 51us/sample - loss: 0.8234 - coeff_determination: 0.6423 - val_loss: 0.9737 - val_coeff_determination: 0.5722\n",
      "Epoch 137/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8337 - coeff_determination: 0.6428 - val_loss: 0.9759 - val_coeff_determination: 0.5766\n",
      "Epoch 138/300\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.8218 - coeff_determination: 0.6425 - val_loss: 0.9681 - val_coeff_determination: 0.5789\n",
      "Epoch 139/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.8143 - coeff_determination: 0.6410 - val_loss: 0.9801 - val_coeff_determination: 0.5737\n",
      "Epoch 140/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8342 - coeff_determination: 0.6402 - val_loss: 0.9660 - val_coeff_determination: 0.5976\n",
      "Epoch 141/300\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.8309 - coeff_determination: 0.6402 - val_loss: 0.9876 - val_coeff_determination: 0.5812\n",
      "Epoch 142/300\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.8306 - coeff_determination: 0.6409 - val_loss: 0.9852 - val_coeff_determination: 0.5818\n",
      "Epoch 143/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.8223 - coeff_determination: 0.6432 - val_loss: 0.9715 - val_coeff_determination: 0.5867\n",
      "Epoch 144/300\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.8304 - coeff_determination: 0.6399 - val_loss: 0.9899 - val_coeff_determination: 0.5758\n",
      "Epoch 145/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.8275 - coeff_determination: 0.6422 - val_loss: 0.9882 - val_coeff_determination: 0.5709\n",
      "Epoch 146/300\n",
      "128000/128000 [==============================] - 7s 58us/sample - loss: 0.8151 - coeff_determination: 0.6449 - val_loss: 0.9815 - val_coeff_determination: 0.5717\n",
      "Epoch 147/300\n",
      "128000/128000 [==============================] - 10s 78us/sample - loss: 0.8262 - coeff_determination: 0.6435 - val_loss: 0.9724 - val_coeff_determination: 0.5863\n",
      "Epoch 148/300\n",
      "128000/128000 [==============================] - 8s 65us/sample - loss: 0.8117 - coeff_determination: 0.6414 - val_loss: 0.9775 - val_coeff_determination: 0.5818\n",
      "Epoch 149/300\n",
      "128000/128000 [==============================] - 8s 62us/sample - loss: 0.8361 - coeff_determination: 0.6428 - val_loss: 0.9804 - val_coeff_determination: 0.5810\n",
      "Epoch 150/300\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.8145 - coeff_determination: 0.6437 - val_loss: 0.9670 - val_coeff_determination: 0.5920\n",
      "Epoch 151/300\n",
      "128000/128000 [==============================] - 11s 83us/sample - loss: 0.8324 - coeff_determination: 0.6427 - val_loss: 0.9886 - val_coeff_determination: 0.5738\n",
      "Epoch 152/300\n",
      "128000/128000 [==============================] - 8s 61us/sample - loss: 0.8073 - coeff_determination: 0.6394 - val_loss: 0.9683 - val_coeff_determination: 0.5815\n",
      "Epoch 153/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8180 - coeff_determination: 0.6405 - val_loss: 0.9699 - val_coeff_determination: 0.5757\n",
      "Epoch 154/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8174 - coeff_determination: 0.6447 - val_loss: 0.9719 - val_coeff_determination: 0.5981\n",
      "Epoch 155/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8155 - coeff_determination: 0.6447 - val_loss: 0.9700 - val_coeff_determination: 0.5813\n",
      "Epoch 156/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8030 - coeff_determination: 0.6463 - val_loss: 0.9766 - val_coeff_determination: 0.5840\n",
      "Epoch 157/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8122 - coeff_determination: 0.6410 - val_loss: 0.9812 - val_coeff_determination: 0.5834\n",
      "Epoch 158/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8259 - coeff_determination: 0.6421 - val_loss: 0.9776 - val_coeff_determination: 0.5751\n",
      "Epoch 159/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8054 - coeff_determination: 0.6412 - val_loss: 0.9822 - val_coeff_determination: 0.5818\n",
      "Epoch 160/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8139 - coeff_determination: 0.6461 - val_loss: 0.9873 - val_coeff_determination: 0.5839\n",
      "Epoch 161/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.8171 - coeff_determination: 0.6464 - val_loss: 0.9763 - val_coeff_determination: 0.5856\n",
      "Epoch 162/300\n",
      "128000/128000 [==============================] - 6s 50us/sample - loss: 0.8033 - coeff_determination: 0.6427 - val_loss: 0.9680 - val_coeff_determination: 0.5854\n",
      "Epoch 163/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.8162 - coeff_determination: 0.6422 - val_loss: 0.9686 - val_coeff_determination: 0.5861\n",
      "Epoch 164/300\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.8137 - coeff_determination: 0.6441 - val_loss: 0.9780 - val_coeff_determination: 0.5815\n",
      "Epoch 165/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8055 - coeff_determination: 0.6446 - val_loss: 0.9767 - val_coeff_determination: 0.5849\n",
      "Epoch 166/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8034 - coeff_determination: 0.6382 - val_loss: 0.9838 - val_coeff_determination: 0.5805\n",
      "Epoch 167/300\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.8182 - coeff_determination: 0.6425 - val_loss: 0.9758 - val_coeff_determination: 0.5808 0s - loss: 0.8239 - coeff_\n",
      "Epoch 168/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8140 - coeff_determination: 0.6442 - val_loss: 0.9716 - val_coeff_determination: 0.5941\n",
      "Epoch 169/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.8103 - coeff_determination: 0.6434 - val_loss: 0.9775 - val_coeff_determination: 0.5869\n",
      "Epoch 170/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8250 - coeff_determination: 0.6451 - val_loss: 0.9863 - val_coeff_determination: 0.5826\n",
      "Epoch 171/300\n",
      "128000/128000 [==============================] - 6s 49us/sample - loss: 0.8018 - coeff_determination: 0.6438 - val_loss: 0.9768 - val_coeff_determination: 0.5849\n",
      "Epoch 172/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8051 - coeff_determination: 0.6414 - val_loss: 0.9692 - val_coeff_determination: 0.5773\n",
      "Epoch 173/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8266 - coeff_determination: 0.6448 - val_loss: 0.9801 - val_coeff_determination: 0.5777\n",
      "Epoch 174/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.7987 - coeff_determination: 0.6447 - val_loss: 0.9771 - val_coeff_determination: 0.5773\n",
      "Epoch 175/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.8039 - coeff_determination: 0.6420 - val_loss: 0.9782 - val_coeff_determination: 0.5835\n",
      "Epoch 176/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8095 - coeff_determination: 0.6459 - val_loss: 0.9695 - val_coeff_determination: 0.5898\n",
      "Epoch 177/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8006 - coeff_determination: 0.6465 - val_loss: 0.9789 - val_coeff_determination: 0.5852\n",
      "Epoch 178/300\n",
      "128000/128000 [==============================] - 7s 58us/sample - loss: 0.8081 - coeff_determination: 0.6469 - val_loss: 0.9917 - val_coeff_determination: 0.5778\n",
      "Epoch 179/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8192 - coeff_determination: 0.6463 - val_loss: 0.9789 - val_coeff_determination: 0.5693\n",
      "Epoch 180/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.7989 - coeff_determination: 0.6448 - val_loss: 0.9695 - val_coeff_determination: 0.5904\n",
      "Epoch 181/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8078 - coeff_determination: 0.6446 - val_loss: 0.9774 - val_coeff_determination: 0.5847\n",
      "Epoch 182/300\n",
      "128000/128000 [==============================] - 6s 51us/sample - loss: 0.7983 - coeff_determination: 0.6456 - val_loss: 0.9763 - val_coeff_determination: 0.5909\n",
      "Epoch 183/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8112 - coeff_determination: 0.6483 - val_loss: 0.9680 - val_coeff_determination: 0.5893\n",
      "Epoch 184/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.8093 - coeff_determination: 0.6464 - val_loss: 0.9701 - val_coeff_determination: 0.5914\n",
      "Epoch 185/300\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.8098 - coeff_determination: 0.6469 - val_loss: 0.9716 - val_coeff_determination: 0.5848\n",
      "Epoch 186/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.7987 - coeff_determination: 0.6402 - val_loss: 1.0007 - val_coeff_determination: 0.5653\n",
      "Epoch 187/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8065 - coeff_determination: 0.6460 - val_loss: 0.9741 - val_coeff_determination: 0.5831\n",
      "Epoch 188/300\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.8080 - coeff_determination: 0.6491 - val_loss: 0.9771 - val_coeff_determination: 0.5818\n",
      "Epoch 189/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8062 - coeff_determination: 0.6421 - val_loss: 0.9820 - val_coeff_determination: 0.5758\n",
      "Epoch 190/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.7957 - coeff_determination: 0.6474 - val_loss: 0.9970 - val_coeff_determination: 0.5743\n",
      "Epoch 191/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.7988 - coeff_determination: 0.6447 - val_loss: 0.9865 - val_coeff_determination: 0.5827\n",
      "Epoch 192/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8150 - coeff_determination: 0.6486 - val_loss: 0.9687 - val_coeff_determination: 0.5852\n",
      "Epoch 193/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8033 - coeff_determination: 0.6477 - val_loss: 0.9756 - val_coeff_determination: 0.5858\n",
      "Epoch 194/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.7980 - coeff_determination: 0.6440 - val_loss: 0.9811 - val_coeff_determination: 0.5722\n",
      "Epoch 195/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8014 - coeff_determination: 0.6449 - val_loss: 0.9926 - val_coeff_determination: 0.5870\n",
      "Epoch 196/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.8144 - coeff_determination: 0.6476 - val_loss: 0.9700 - val_coeff_determination: 0.5734\n",
      "Epoch 197/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8098 - coeff_determination: 0.6465 - val_loss: 0.9765 - val_coeff_determination: 0.5786\n",
      "Epoch 198/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.7956 - coeff_determination: 0.6467 - val_loss: 0.9845 - val_coeff_determination: 0.5806\n",
      "Epoch 199/300\n",
      "128000/128000 [==============================] - 7s 51us/sample - loss: 0.8188 - coeff_determination: 0.6442 - val_loss: 0.9770 - val_coeff_determination: 0.5886\n",
      "Epoch 200/300\n",
      "128000/128000 [==============================] - 7s 52us/sample - loss: 0.7975 - coeff_determination: 0.6426 - val_loss: 0.9819 - val_coeff_determination: 0.5822\n",
      "Epoch 201/300\n",
      "126944/128000 [============================>.] - ETA: 0s - loss: 0.8063 - coeff_determination: 0.6447\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8080 - coeff_determination: 0.6445 - val_loss: 0.9769 - val_coeff_determination: 0.5792\n",
      "Epoch 202/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8035 - coeff_determination: 0.6469 - val_loss: 0.9774 - val_coeff_determination: 0.5820\n",
      "Epoch 203/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8030 - coeff_determination: 0.6480 - val_loss: 0.9819 - val_coeff_determination: 0.5921\n",
      "Epoch 204/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.7960 - coeff_determination: 0.6484 - val_loss: 0.9733 - val_coeff_determination: 0.5901\n",
      "Epoch 205/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8157 - coeff_determination: 0.6482 - val_loss: 0.9700 - val_coeff_determination: 0.5830\n",
      "Epoch 206/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.8011 - coeff_determination: 0.6475 - val_loss: 0.9717 - val_coeff_determination: 0.5876\n",
      "Epoch 207/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.7963 - coeff_determination: 0.6507 - val_loss: 0.9784 - val_coeff_determination: 0.5859\n",
      "Epoch 208/300\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.8063 - coeff_determination: 0.6465 - val_loss: 0.9877 - val_coeff_determination: 0.5798\n",
      "Epoch 209/300\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.7958 - coeff_determination: 0.6486 - val_loss: 0.9810 - val_coeff_determination: 0.5797\n",
      "Epoch 210/300\n",
      "128000/128000 [==============================] - 6s 51us/sample - loss: 0.8087 - coeff_determination: 0.6460 - val_loss: 0.9796 - val_coeff_determination: 0.5772\n",
      "Epoch 211/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.7928 - coeff_determination: 0.6485 - val_loss: 0.9937 - val_coeff_determination: 0.5730\n",
      "Epoch 212/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.7966 - coeff_determination: 0.6482 - val_loss: 0.9868 - val_coeff_determination: 0.5866\n",
      "Epoch 213/300\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.7960 - coeff_determination: 0.6491 - val_loss: 0.9745 - val_coeff_determination: 0.5821\n",
      "Epoch 214/300\n",
      "128000/128000 [==============================] - 7s 53us/sample - loss: 0.8010 - coeff_determination: 0.6515 - val_loss: 0.9937 - val_coeff_determination: 0.5836\n",
      "Epoch 215/300\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.8007 - coeff_determination: 0.6527 - val_loss: 0.9894 - val_coeff_determination: 0.5666\n",
      "Epoch 216/300\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.7927 - coeff_determination: 0.6491 - val_loss: 0.9774 - val_coeff_determination: 0.5716\n",
      "Epoch 217/300\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.7931 - coeff_determination: 0.6449 - val_loss: 0.9770 - val_coeff_determination: 0.5818\n",
      "Epoch 218/300\n",
      "128000/128000 [==============================] - 9s 72us/sample - loss: 0.8009 - coeff_determination: 0.6503 - val_loss: 1.0006 - val_coeff_determination: 0.5696\n",
      "Epoch 219/300\n",
      "128000/128000 [==============================] - 9s 70us/sample - loss: 0.8031 - coeff_determination: 0.6460 - val_loss: 0.9935 - val_coeff_determination: 0.5620\n",
      "Epoch 220/300\n",
      "128000/128000 [==============================] - 8s 66us/sample - loss: 0.7925 - coeff_determination: 0.6529 - val_loss: 1.0069 - val_coeff_determination: 0.5560\n",
      "Epoch 221/300\n",
      "128000/128000 [==============================] - 8s 66us/sample - loss: 0.8105 - coeff_determination: 0.6493 - val_loss: 0.9890 - val_coeff_determination: 0.5743\n",
      "Epoch 222/300\n",
      "128000/128000 [==============================] - 8s 59us/sample - loss: 0.7913 - coeff_determination: 0.6475 - val_loss: 0.9916 - val_coeff_determination: 0.5746\n",
      "Epoch 223/300\n",
      "128000/128000 [==============================] - 9s 69us/sample - loss: 0.8066 - coeff_determination: 0.6467 - val_loss: 0.9840 - val_coeff_determination: 0.5797\n",
      "Epoch 224/300\n",
      "128000/128000 [==============================] - 9s 70us/sample - loss: 0.8018 - coeff_determination: 0.6485 - val_loss: 0.9982 - val_coeff_determination: 0.5802\n",
      "Epoch 225/300\n",
      "128000/128000 [==============================] - 8s 64us/sample - loss: 0.8061 - coeff_determination: 0.6487 - val_loss: 0.9830 - val_coeff_determination: 0.5869\n",
      "Epoch 226/300\n",
      "128000/128000 [==============================] - 8s 60us/sample - loss: 0.7886 - coeff_determination: 0.6540 - val_loss: 0.9704 - val_coeff_determination: 0.5852\n",
      "Epoch 227/300\n",
      "128000/128000 [==============================] - 8s 60us/sample - loss: 0.7881 - coeff_determination: 0.6532 - val_loss: 0.9969 - val_coeff_determination: 0.5682\n",
      "Epoch 228/300\n",
      "128000/128000 [==============================] - 9s 69us/sample - loss: 0.7950 - coeff_determination: 0.6499 - val_loss: 0.9903 - val_coeff_determination: 0.5607\n",
      "Epoch 229/300\n",
      "128000/128000 [==============================] - 7s 54us/sample - loss: 0.7942 - coeff_determination: 0.6512 - val_loss: 0.9951 - val_coeff_determination: 0.5807\n",
      "Epoch 230/300\n",
      "128000/128000 [==============================] - 7s 55us/sample - loss: 0.8000 - coeff_determination: 0.6464 - val_loss: 0.9767 - val_coeff_determination: 0.5828\n",
      "Epoch 231/300\n",
      "128000/128000 [==============================] - 9s 66us/sample - loss: 0.7841 - coeff_determination: 0.6509 - val_loss: 0.9795 - val_coeff_determination: 0.5701\n",
      "Epoch 232/300\n",
      "128000/128000 [==============================] - 8s 63us/sample - loss: 0.8004 - coeff_determination: 0.6510 - val_loss: 0.9726 - val_coeff_determination: 0.5875\n",
      "Epoch 233/300\n",
      "128000/128000 [==============================] - 9s 67us/sample - loss: 0.7923 - coeff_determination: 0.6493 - val_loss: 0.9821 - val_coeff_determination: 0.5810\n",
      "Epoch 234/300\n",
      "128000/128000 [==============================] - 9s 73us/sample - loss: 0.7992 - coeff_determination: 0.6507 - val_loss: 0.9985 - val_coeff_determination: 0.5795\n",
      "Epoch 235/300\n",
      "128000/128000 [==============================] - 8s 64us/sample - loss: 0.7998 - coeff_determination: 0.6495 - val_loss: 0.9864 - val_coeff_determination: 0.5648\n",
      "Epoch 236/300\n",
      "128000/128000 [==============================] - 8s 64us/sample - loss: 0.7910 - coeff_determination: 0.6539 - val_loss: 1.0001 - val_coeff_determination: 0.5807\n",
      "Epoch 237/300\n",
      "128000/128000 [==============================] - 9s 70us/sample - loss: 0.8019 - coeff_determination: 0.6540 - val_loss: 0.9707 - val_coeff_determination: 0.5878\n",
      "Epoch 238/300\n",
      "128000/128000 [==============================] - 9s 69us/sample - loss: 0.7971 - coeff_determination: 0.6539 - val_loss: 0.9772 - val_coeff_determination: 0.5757\n",
      "Epoch 239/300\n",
      "128000/128000 [==============================] - 9s 73us/sample - loss: 0.7854 - coeff_determination: 0.6530 - val_loss: 0.9793 - val_coeff_determination: 0.5762\n",
      "Epoch 240/300\n",
      "128000/128000 [==============================] - 8s 59us/sample - loss: 0.7957 - coeff_determination: 0.6506 - val_loss: 0.9863 - val_coeff_determination: 0.5875\n",
      "Epoch 241/300\n",
      "128000/128000 [==============================] - 8s 61us/sample - loss: 0.8070 - coeff_determination: 0.6489 - val_loss: 0.9790 - val_coeff_determination: 0.5836\n",
      "Epoch 242/300\n",
      "128000/128000 [==============================] - 8s 60us/sample - loss: 0.7839 - coeff_determination: 0.6508 - val_loss: 0.9727 - val_coeff_determination: 0.5755\n",
      "Epoch 243/300\n",
      "128000/128000 [==============================] - 8s 66us/sample - loss: 0.7924 - coeff_determination: 0.6514 - val_loss: 0.9893 - val_coeff_determination: 0.5767\n",
      "Epoch 244/300\n",
      "128000/128000 [==============================] - 9s 67us/sample - loss: 0.8075 - coeff_determination: 0.6516 - val_loss: 0.9969 - val_coeff_determination: 0.5651\n",
      "Epoch 245/300\n",
      "128000/128000 [==============================] - 7s 58us/sample - loss: 0.7857 - coeff_determination: 0.6504 - val_loss: 0.9761 - val_coeff_determination: 0.5833\n",
      "Epoch 246/300\n",
      "128000/128000 [==============================] - 8s 65us/sample - loss: 0.7916 - coeff_determination: 0.6506 - val_loss: 0.9781 - val_coeff_determination: 0.5756\n",
      "Epoch 247/300\n",
      "128000/128000 [==============================] - 11s 86us/sample - loss: 0.8007 - coeff_determination: 0.6483 - val_loss: 0.9879 - val_coeff_determination: 0.5765 0.7841 - coeff\n",
      "Epoch 248/300\n",
      "128000/128000 [==============================] - 9s 67us/sample - loss: 0.7875 - coeff_determination: 0.6554 - val_loss: 0.9825 - val_coeff_determination: 0.5801\n",
      "Epoch 249/300\n",
      "128000/128000 [==============================] - 8s 63us/sample - loss: 0.7979 - coeff_determination: 0.6523 - val_loss: 0.9755 - val_coeff_determination: 0.5818\n",
      "Epoch 250/300\n",
      "128000/128000 [==============================] - 9s 73us/sample - loss: 0.7890 - coeff_determination: 0.6515 - val_loss: 0.9752 - val_coeff_determination: 0.5833\n",
      "Epoch 251/300\n",
      "128000/128000 [==============================] - 8s 66us/sample - loss: 0.7886 - coeff_determination: 0.6475 - val_loss: 0.9833 - val_coeff_determination: 0.5753\n",
      "Epoch 252/300\n",
      "128000/128000 [==============================] - 8s 66us/sample - loss: 0.7935 - coeff_determination: 0.6535 - val_loss: 0.9824 - val_coeff_determination: 0.5779\n",
      "Epoch 253/300\n",
      "128000/128000 [==============================] - 8s 66us/sample - loss: 0.7852 - coeff_determination: 0.6522 - val_loss: 0.9829 - val_coeff_determination: 0.5798\n",
      "Epoch 254/300\n",
      "128000/128000 [==============================] - 8s 66us/sample - loss: 0.8000 - coeff_determination: 0.6433 - val_loss: 0.9802 - val_coeff_determination: 0.5824\n",
      "Epoch 255/300\n",
      "128000/128000 [==============================] - 9s 70us/sample - loss: 0.7839 - coeff_determination: 0.6487 - val_loss: 1.0000 - val_coeff_determination: 0.5690\n",
      "Epoch 256/300\n",
      "128000/128000 [==============================] - 8s 62us/sample - loss: 0.7889 - coeff_determination: 0.6508 - val_loss: 0.9772 - val_coeff_determination: 0.5812\n",
      "Epoch 257/300\n",
      "128000/128000 [==============================] - 9s 68us/sample - loss: 0.7998 - coeff_determination: 0.6484 - val_loss: 0.9837 - val_coeff_determination: 0.5899\n",
      "Epoch 258/300\n",
      "128000/128000 [==============================] - 9s 67us/sample - loss: 0.7933 - coeff_determination: 0.6472 - val_loss: 0.9928 - val_coeff_determination: 0.5724\n",
      "Epoch 259/300\n",
      "128000/128000 [==============================] - 8s 63us/sample - loss: 0.7933 - coeff_determination: 0.6497 - val_loss: 0.9853 - val_coeff_determination: 0.5774\n",
      "Epoch 260/300\n",
      "128000/128000 [==============================] - 8s 66us/sample - loss: 0.7842 - coeff_determination: 0.6514 - val_loss: 0.9815 - val_coeff_determination: 0.5814\n",
      "Epoch 261/300\n",
      "128000/128000 [==============================] - 9s 68us/sample - loss: 0.7905 - coeff_determination: 0.6485 - val_loss: 0.9916 - val_coeff_determination: 0.5751\n",
      "Epoch 262/300\n",
      "128000/128000 [==============================] - 8s 65us/sample - loss: 0.7866 - coeff_determination: 0.6532 - val_loss: 0.9863 - val_coeff_determination: 0.5793\n",
      "Epoch 263/300\n",
      "128000/128000 [==============================] - 9s 70us/sample - loss: 0.7881 - coeff_determination: 0.6539 - val_loss: 0.9862 - val_coeff_determination: 0.5851\n",
      "Epoch 264/300\n",
      "128000/128000 [==============================] - 12s 91us/sample - loss: 0.7808 - coeff_determination: 0.6503 - val_loss: 0.9949 - val_coeff_determination: 0.5711\n",
      "Epoch 265/300\n",
      "128000/128000 [==============================] - 12s 90us/sample - loss: 0.7815 - coeff_determination: 0.6498 - val_loss: 1.0011 - val_coeff_determination: 0.5814\n",
      "Epoch 266/300\n",
      "128000/128000 [==============================] - 9s 69us/sample - loss: 0.7859 - coeff_determination: 0.6500 - val_loss: 0.9987 - val_coeff_determination: 0.5842\n",
      "Epoch 267/300\n",
      "128000/128000 [==============================] - 10s 77us/sample - loss: 0.7830 - coeff_determination: 0.6507 - val_loss: 0.9778 - val_coeff_determination: 0.5780\n",
      "Epoch 268/300\n",
      "128000/128000 [==============================] - 10s 80us/sample - loss: 0.7822 - coeff_determination: 0.6480 - val_loss: 0.9816 - val_coeff_determination: 0.5810\n",
      "Epoch 269/300\n",
      "128000/128000 [==============================] - 10s 77us/sample - loss: 0.7941 - coeff_determination: 0.6493 - val_loss: 0.9760 - val_coeff_determination: 0.5874\n",
      "Epoch 270/300\n",
      "128000/128000 [==============================] - 11s 84us/sample - loss: 0.7965 - coeff_determination: 0.6535 - val_loss: 0.9984 - val_coeff_determination: 0.5705\n",
      "Epoch 271/300\n",
      "128000/128000 [==============================] - 9s 67us/sample - loss: 0.7803 - coeff_determination: 0.6512 - val_loss: 0.9778 - val_coeff_determination: 0.5758\n",
      "Epoch 272/300\n",
      "128000/128000 [==============================] - 8s 66us/sample - loss: 0.7918 - coeff_determination: 0.6543 - val_loss: 0.9921 - val_coeff_determination: 0.5716\n",
      "Epoch 273/300\n",
      "128000/128000 [==============================] - 8s 60us/sample - loss: 0.7949 - coeff_determination: 0.6513 - val_loss: 0.9885 - val_coeff_determination: 0.5705\n",
      "Epoch 274/300\n",
      "128000/128000 [==============================] - 8s 63us/sample - loss: 0.7838 - coeff_determination: 0.6517 - val_loss: 0.9975 - val_coeff_determination: 0.5746\n",
      "Epoch 275/300\n",
      "128000/128000 [==============================] - 9s 74us/sample - loss: 0.7866 - coeff_determination: 0.6510 - val_loss: 1.0080 - val_coeff_determination: 0.5723\n",
      "Epoch 276/300\n",
      "128000/128000 [==============================] - 8s 62us/sample - loss: 0.7849 - coeff_determination: 0.6515 - val_loss: 0.9859 - val_coeff_determination: 0.5811\n",
      "Epoch 277/300\n",
      "128000/128000 [==============================] - 9s 72us/sample - loss: 0.7874 - coeff_determination: 0.6495 - val_loss: 0.9815 - val_coeff_determination: 0.5813\n",
      "Epoch 278/300\n",
      "128000/128000 [==============================] - 9s 69us/sample - loss: 0.7912 - coeff_determination: 0.6529 - val_loss: 0.9834 - val_coeff_determination: 0.5815\n",
      "Epoch 279/300\n",
      "128000/128000 [==============================] - 8s 61us/sample - loss: 0.7834 - coeff_determination: 0.6522 - val_loss: 1.0197 - val_coeff_determination: 0.5576\n",
      "Epoch 280/300\n",
      "128000/128000 [==============================] - 7s 59us/sample - loss: 0.7900 - coeff_determination: 0.6553 - val_loss: 0.9974 - val_coeff_determination: 0.5749\n",
      "Epoch 281/300\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.7957 - coeff_determination: 0.6533 - val_loss: 0.9922 - val_coeff_determination: 0.5830\n",
      "Epoch 282/300\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.7771 - coeff_determination: 0.6522 - val_loss: 0.9777 - val_coeff_determination: 0.5732\n",
      "Epoch 283/300\n",
      "128000/128000 [==============================] - 9s 69us/sample - loss: 0.7844 - coeff_determination: 0.6482 - val_loss: 0.9911 - val_coeff_determination: 0.5840\n",
      "Epoch 284/300\n",
      "128000/128000 [==============================] - 8s 65us/sample - loss: 0.7856 - coeff_determination: 0.6535 - val_loss: 0.9879 - val_coeff_determination: 0.5847\n",
      "Epoch 285/300\n",
      "128000/128000 [==============================] - 9s 68us/sample - loss: 0.7812 - coeff_determination: 0.6524 - val_loss: 0.9838 - val_coeff_determination: 0.5777\n",
      "Epoch 286/300\n",
      "128000/128000 [==============================] - 10s 77us/sample - loss: 0.7808 - coeff_determination: 0.6547 - val_loss: 0.9867 - val_coeff_determination: 0.5719\n",
      "Epoch 287/300\n",
      "128000/128000 [==============================] - 8s 63us/sample - loss: 0.7930 - coeff_determination: 0.6543 - val_loss: 1.0075 - val_coeff_determination: 0.5695\n",
      "Epoch 288/300\n",
      "128000/128000 [==============================] - 9s 67us/sample - loss: 0.7807 - coeff_determination: 0.6549 - val_loss: 0.9864 - val_coeff_determination: 0.5783\n",
      "Epoch 289/300\n",
      "128000/128000 [==============================] - 9s 69us/sample - loss: 0.7922 - coeff_determination: 0.6500 - val_loss: 0.9840 - val_coeff_determination: 0.5742\n",
      "Epoch 290/300\n",
      "128000/128000 [==============================] - 9s 67us/sample - loss: 0.7760 - coeff_determination: 0.6556 - val_loss: 0.9820 - val_coeff_determination: 0.5872\n",
      "Epoch 291/300\n",
      "128000/128000 [==============================] - 8s 62us/sample - loss: 0.7816 - coeff_determination: 0.6526 - val_loss: 0.9788 - val_coeff_determination: 0.5804\n",
      "Epoch 292/300\n",
      "128000/128000 [==============================] - 9s 72us/sample - loss: 0.7880 - coeff_determination: 0.6519 - val_loss: 1.0129 - val_coeff_determination: 0.5663\n",
      "Epoch 293/300\n",
      "128000/128000 [==============================] - 8s 66us/sample - loss: 0.7805 - coeff_determination: 0.6558 - val_loss: 0.9913 - val_coeff_determination: 0.5797\n",
      "Epoch 294/300\n",
      "128000/128000 [==============================] - 8s 65us/sample - loss: 0.7911 - coeff_determination: 0.6533 - val_loss: 0.9807 - val_coeff_determination: 0.5792\n",
      "Epoch 295/300\n",
      "128000/128000 [==============================] - 8s 63us/sample - loss: 0.7835 - coeff_determination: 0.6522 - val_loss: 0.9967 - val_coeff_determination: 0.5757\n",
      "Epoch 296/300\n",
      "128000/128000 [==============================] - 9s 70us/sample - loss: 0.7797 - coeff_determination: 0.6556 - val_loss: 0.9797 - val_coeff_determination: 0.5797\n",
      "Epoch 297/300\n",
      "128000/128000 [==============================] - 8s 64us/sample - loss: 0.7814 - coeff_determination: 0.6553 - val_loss: 0.9963 - val_coeff_determination: 0.5742\n",
      "Epoch 298/300\n",
      "128000/128000 [==============================] - 10s 78us/sample - loss: 0.7955 - coeff_determination: 0.6544 - val_loss: 0.9887 - val_coeff_determination: 0.5808\n",
      "Epoch 299/300\n",
      "128000/128000 [==============================] - 10s 77us/sample - loss: 0.7815 - coeff_determination: 0.6506 - val_loss: 0.9866 - val_coeff_determination: 0.5774\n",
      "Epoch 300/300\n",
      "128000/128000 [==============================] - 9s 71us/sample - loss: 0.7860 - coeff_determination: 0.6567 - val_loss: 0.9824 - val_coeff_determination: 0.5789\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model()\n",
    "EPOCHS = 300\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_coeff_determination', patience=10)\n",
    "\n",
    "history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n",
    "                    validation_split = 0.2, verbose=1, callbacks=[PrintDot()])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "40000/40000 - 1s - loss: 0.9615 - coeff_determination: 0.5615\n",
      "Testing set Mean Abs Error:  0.56 Rate_spread\n"
     ]
    }
   ],
   "source": [
    "loss, mae= model.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f} Rate_spread\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "[5.2528076 2.043283  1.859252  ... 0.9265888 1.2206229 1.1376678]\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(normed_test).flatten()\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coord = []\n",
    "y_coord = []\n",
    "\n",
    "for i in range(len(y)):\n",
    "    #print(\"X=%s, Predicted=%s\" % (i, y[i]))\n",
    "    x_coord.append(i)\n",
    "    y_coord.append(test_predictions[i])\n",
    "\n",
    "np.savetxt('predict3.csv', np.vstack((x_coord,y_coord)).T, delimiter=', ',fmt='%d, %f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
